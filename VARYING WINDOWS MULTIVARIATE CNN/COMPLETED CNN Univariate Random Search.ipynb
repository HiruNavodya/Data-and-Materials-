{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sNHYqgwRxYZ","executionInfo":{"status":"ok","timestamp":1752552656494,"user_tz":-330,"elapsed":7183,"user":{"displayName":"Hiruni Navodya","userId":"04110396827198336368"}},"outputId":"e214f200-fdda-4a13-dc01-f5c1c6363742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n","Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"]}]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import TimeSeriesSplit\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, Dense, Flatten\n","from tensorflow.keras.optimizers import Adam\n","import random\n","import tensorflow as tf\n","\n","# Set random seeds for reproducibility\n","random_seed = 42\n","np.random.seed(random_seed)\n","random.seed(random_seed)\n","tf.random.set_seed(random_seed)\n","\n","# Load dataset\n","sheet_id = \"1j_Euo80PrGckVDVr2hTG9zZebxJD0TSC\"\n","sheet_name = \"Sheet1\"\n","csv_url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n","df = pd.read_csv(csv_url)\n","\n","# Preprocessing\n","df = df.set_index('Date')\n","df = df.drop(columns=[\"YEAR\", \"MO\", \"DY\"])\n","target_column = \"WS10M\"\n","scaler = MinMaxScaler()\n","df[target_column] = scaler.fit_transform(df[[target_column]])\n","series = df[target_column].values\n","\n","# Function to create sequences\n","def create_sequences(data, window_size):\n","    X, y = [], []\n","    for i in range(len(data) - window_size):\n","        X.append(data[i:i + window_size])\n","        y.append(data[i + window_size])\n","    return np.array(X), np.array(y)\n","\n","# Random search parameter space\n","param_space = {\n","    'filters': [32, 64, 96, 128],\n","    'kernel_size': [1, 2, 3, 4, 5],\n","    'lr': [1e-4, 3e-4, 1e-3, 3e-3, 1e-2],\n","    'epochs': [10, 15, 20, 25, 30],\n","    'batch_size': [8, 16, 32]\n","}\n","\n","# Loop over lags (window sizes) from 1 to 14\n","results = []\n","\n","for lag in range(1, 15):\n","    print(f\"\\n\\n### LAG WINDOW: {lag} ###\")\n","\n","    # Create sequences\n","    X, y = create_sequences(series, lag)\n","    split_index = int(len(X) * 0.8)\n","    X_train, X_test = X[:split_index], X[split_index:]\n","    y_train, y_test = y[:split_index], y[split_index:]\n","\n","    X_train = X_train[..., np.newaxis]\n","    X_test = X_test[..., np.newaxis]\n","\n","    # Reset random seed for each lag to ensure consistent comparison\n","    np.random.seed(random_seed)\n","    random.seed(random_seed)\n","    tf.random.set_seed(random_seed)\n","\n","    # Random search implementation\n","    best_val_loss = float('inf')\n","    best_params = None\n","\n","    # Number of random trials\n","    n_trials = 20\n","\n","    for trial_num in range(n_trials):\n","        # Set trial-specific seed for reproducible random sampling\n","        trial_seed = random_seed + lag * 100 + trial_num\n","        random.seed(trial_seed)\n","\n","        # Sample random parameters\n","        params = {\n","            'filters': random.choice(param_space['filters']),\n","            'kernel_size': random.choice([k for k in param_space['kernel_size'] if k <= lag]),\n","            'lr': random.choice(param_space['lr']),\n","            'epochs': random.choice(param_space['epochs']),\n","            'batch_size': random.choice(param_space['batch_size'])\n","        }\n","\n","        tscv = TimeSeriesSplit(n_splits=3)\n","        val_losses = []\n","\n","        for train_idx, val_idx in tscv.split(X_train):\n","            X_t, X_v = X_train[train_idx], X_train[val_idx]\n","            y_t, y_v = y_train[train_idx], y_train[val_idx]\n","\n","            # Reset model weights for each fold\n","            tf.keras.backend.clear_session()\n","            np.random.seed(trial_seed)\n","            tf.random.set_seed(trial_seed)\n","\n","            # Create model with current parameters\n","            model = Sequential()\n","            model.add(Conv1D(filters=params['filters'],\n","                             kernel_size=params['kernel_size'],\n","                             activation='relu',\n","                             input_shape=X_train.shape[1:]))\n","            model.add(Flatten())\n","            model.add(Dense(1))\n","            model.compile(optimizer=Adam(learning_rate=params['lr']),\n","                          loss='mse')\n","\n","            model.fit(X_t, y_t,\n","                      epochs=params['epochs'],\n","                      batch_size=params['batch_size'],\n","                      verbose=0)\n","\n","            val_loss = model.evaluate(X_v, y_v, verbose=0)\n","            val_losses.append(val_loss)\n","\n","        mean_val_loss = np.mean(val_losses)\n","\n","        if mean_val_loss < best_val_loss:\n","            best_val_loss = mean_val_loss\n","            best_params = params\n","\n","    print(f\"Best params for lag {lag}: {best_params}\")\n","\n","    # Train final model with best parameters\n","    tf.keras.backend.clear_session()\n","    np.random.seed(random_seed + lag * 1000)  # Different seed for final model\n","    tf.random.set_seed(random_seed + lag * 1000)\n","\n","    model = Sequential()\n","    model.add(Conv1D(filters=best_params['filters'],\n","                     kernel_size=best_params['kernel_size'],\n","                     activation='relu',\n","                     input_shape=X_train.shape[1:]))\n","    model.add(Flatten())\n","    model.add(Dense(1))\n","    model.compile(optimizer=Adam(learning_rate=best_params['lr']),\n","                  loss='mse')\n","    model.fit(X_train, y_train, epochs=best_params['epochs'],\n","              batch_size=best_params['batch_size'], verbose=0)\n","\n","    # Predict\n","    y_pred = model.predict(X_test)\n","    y_pred_inv = scaler.inverse_transform(y_pred)\n","    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n","\n","    # Metrics\n","    mse = mean_squared_error(y_test_inv, y_pred_inv)\n","    rmse = np.sqrt(mse)\n","    mae = mean_absolute_error(y_test_inv, y_pred_inv)\n","    mape = np.mean(np.abs((y_test_inv - y_pred_inv) / y_test_inv)) * 100\n","    r2 = r2_score(y_test_inv, y_pred_inv)\n","\n","    # Store results\n","    results.append({\n","        'Lag': lag,\n","        'MSE': mse,\n","        'RMSE': rmse,\n","        'MAE': mae,\n","        'MAPE': mape,\n","        'R2': r2,\n","        'Params': best_params\n","    })\n","\n","    # Plotting\n","    plt.figure(figsize=(12, 4))\n","    plt.plot(y_test_inv, label='Actual', linewidth=2)\n","    plt.plot(y_pred_inv, label='Predicted', linestyle='--')\n","    plt.title(f'CNN Forecast vs Actual (Lag {lag})')\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"WS10M\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Display all performance metrics\n","results_df = pd.DataFrame(results)\n","print(\"\\nSummary of CNN model performance for each lag window:\\n\")\n","print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Wc240PL0-cDgHWj_VHOvIui8_mjhjm4e"},"id":"B5Pa8yqgRvj-","outputId":"40d2ecec-69b2-4782-8f11-88b351717933","executionInfo":{"status":"ok","timestamp":1752560896615,"user_tz":-330,"elapsed":7695847,"user":{"displayName":"UG Research","userId":"07105397936942907994"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"PK7U8B2BRvgZ"},"execution_count":null,"outputs":[]}]}